{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cgtffot0TPRe"
      },
      "source": [
        "### **PMLDL Assignment 2:** Movie Review Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bM8pWx9aTg4v"
      },
      "source": [
        "IMDB dataset having 50K movie reviews for natural language processing or Text analytics. This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets.\n",
        "\n",
        "![alt text](https://www.samyzaf.com/ML/imdb/imdb2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GV0AvH9DV6U1"
      },
      "source": [
        "In this assignment we are interested in performing a sentiment analysis on the movie reviews. Your tasks are as following:\n",
        "\n",
        "1. **Preprocess** the text and put it in appropriate format (cleaning, tokenization ... as seen in the lab) (20 points)\n",
        "2. Implement **2 models** of your choice (with lstm's , RNN's ...) One with trainable embedding layer and in the second use embeddings from word2vec or Glov in the embedding layer ( you can use library such as gensim) (20 points)\n",
        "3. **Compare** the performance of the two models (5 pts)\n",
        "3. Use **TSNE** or **Umap** to vizualise words and their vectors in the latent space (of the trainable embedding)( 15 points)\n",
        "4. **Report** metrics and loss using tensorbord/comet or any tool you are comfortable with.  (5 points)\n",
        "\n",
        "Clean and documented code (10 points)             \n",
        "Correct method (includes correct loss function , parameters tuning, correct training and testing, accuracy value) 25 points.\n",
        "\n",
        "\n",
        "\n",
        "Remarks :\n",
        "\n",
        "\n",
        "*   Use Pytorch\n",
        "*   Unattached graphs are not counted (0 point)  \n",
        "*   Cheating will result in a severe penalization\n",
        "*   Plagiarism is prohibited\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WguYNQxyi17j"
      },
      "source": [
        "## Reading Data & Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyl19Vgeh-W6",
        "outputId": "f5d50302-540e-4f16-8abd-6c08ab6aa3a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU is available\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# checking if GPU is available\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda:1\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrEY9e0wh-W8",
        "outputId": "aaafead0-e866-48bf-b1bb-6ed636650fc6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'NVIDIA GeForce RTX 3060 Laptop GPU'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.get_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-dcoZqrh-W9",
        "outputId": "e767006f-5bf2-466f-e888-3396e4cf60b4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# reading dataset from csv file downloaded from here: https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
        "df = pd.read_csv('imdb_dataset.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvAEV5C8h-W-"
      },
      "outputs": [],
      "source": [
        "x = df['review'].values\n",
        "y = df['sentiment'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJRJfPlHh-W-",
        "outputId": "8ace2803-a589-40bb-84fc-04a699b4de54"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\pavlo\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "import nltk.tokenize as tokenization\n",
        "\n",
        "def clean_and_tokenize_text(text):\n",
        "\n",
        "    text = text.lower() # lowercasing the text\n",
        "\n",
        "    # cleaning the text from special for the domain but meaningless in terms of sentiment analysis symbols\n",
        "    text = text.replace('<br /><br />', ' ')\n",
        "    text = text.replace('\\'', ' ')\n",
        "    for symbol in '[/(){}\\[\\]\\|@,;]':\n",
        "        text = text.replace(symbol, '')\n",
        "\n",
        "    # tokenizing the text\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwords from text\n",
        "    text = tokenization.word_tokenize(text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsMkJ-57h-W_"
      },
      "outputs": [],
      "source": [
        "for i in range(x.shape[0]):\n",
        "    x[i] = clean_and_tokenize_text(x[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArLoApQ1h-W_"
      },
      "outputs": [],
      "source": [
        "for i in range(y.shape[0]):\n",
        "    if y[i] == \"positive\":\n",
        "        y[i] = 1\n",
        "    else:\n",
        "        y[i] = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYtf83xGi7eh"
      },
      "source": [
        "## Prepare training and testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T55sW61Ii6XN"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_s8OXbyjTSH"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49AIRy7rh-XC"
      },
      "outputs": [],
      "source": [
        "# x_train1 and x_test1 are x_train and x_test modifications prepared specifically for the 1st model\n",
        "x_train1 = tokenizer.texts_to_sequences(x_train)\n",
        "x_test1 = tokenizer.texts_to_sequences(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTNeIKLyh-XC"
      },
      "outputs": [],
      "source": [
        "maxlen = 250 # only keep 250 words from each review; if there are less, use padding\n",
        "x_train1 = pad_sequences(x_train1, maxlen=maxlen)\n",
        "x_test1 = pad_sequences(x_test1, maxlen=maxlen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mltIbq0ph-XC"
      },
      "outputs": [],
      "source": [
        "x_train1 = x_train1.astype('int32')\n",
        "x_test1 = x_test1.astype('int32')\n",
        "y_train = y_train.astype('float32')\n",
        "y_test = y_test.astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sir_ehvYh-XC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "train_data1 = TensorDataset(torch.from_numpy(x_train1), torch.from_numpy(y_train))\n",
        "test_data1 = TensorDataset(torch.from_numpy(x_test1), torch.from_numpy(y_test))\n",
        "\n",
        "batch_size = 50\n",
        "\n",
        "train_loader1 = DataLoader(train_data1, shuffle=True, batch_size=batch_size)\n",
        "test_loader1 = DataLoader(test_data1, shuffle=True, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuDzCm9Th-XC"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "vector_size = 100 # size of embeddings\n",
        "word2vec = Word2Vec(sentences = x, vector_size = vector_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IbgPoLph-XC"
      },
      "outputs": [],
      "source": [
        "# use word2vec embeddings to transform dataset x\n",
        "# pad each review to size maxlen\n",
        "def padding_embeddings(x, word2vec, maxlen, vector_size):\n",
        "    res = []\n",
        "    for review_ind in range(len(x)):\n",
        "        review_embedding = []\n",
        "        for word_ind in range(len(x[review_ind])):\n",
        "            if word_ind < maxlen:\n",
        "                word = x[review_ind][word_ind]\n",
        "                try:\n",
        "                    review_embedding.append(word2vec.wv[word])\n",
        "                except KeyError:\n",
        "                    review_embedding.append([0] * vector_size)\n",
        "        for i in range(maxlen - len(review_embedding)):\n",
        "            review_embedding.append([0] * vector_size)\n",
        "        res.append(review_embedding)\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3UvFmBch-XD"
      },
      "outputs": [],
      "source": [
        "# x_train2 and x_test2 are x_train and x_test modifications prepared specifically for the 2nd model\n",
        "x_train2 = padding_embeddings(x_train, word2vec, 200, vector_size)\n",
        "x_test2 = padding_embeddings(x_test, word2vec, 200, vector_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xil1SBPUh-XD"
      },
      "outputs": [],
      "source": [
        "x_train2 = np.array(x_train2, dtype = \"float32\")\n",
        "x_test2 = np.array(x_test2, dtype = \"float32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLMegfy4h-XD"
      },
      "outputs": [],
      "source": [
        "train_data2 = TensorDataset(torch.from_numpy(x_train2), torch.from_numpy(y_train))\n",
        "test_data2 = TensorDataset(torch.from_numpy(x_test2), torch.from_numpy(y_test))\n",
        "\n",
        "batch_size = 50\n",
        "\n",
        "train_loader2 = DataLoader(train_data2, shuffle=True, batch_size=batch_size)\n",
        "test_loader2 = DataLoader(test_data2, shuffle=True, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Q0seTIhjNqv"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmBoKz1nh-XD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "EMBEDDING_DIM = 200\n",
        "HIDDEN_DIM = 70\n",
        "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
        "\n",
        "class trainable_embedding_model(torch.nn.Module) :\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size) :\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embeddings(x)\n",
        "        x = self.dropout(x)\n",
        "        lstm_out, (ht, ct) = self.lstm(x)\n",
        "        return torch.sigmoid(self.linear(ht[-1]))\n",
        "\n",
        "    def return_embeddings(self, x):\n",
        "        return self.embeddings(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlrPrbl7h-XD"
      },
      "outputs": [],
      "source": [
        "model1 = trainable_embedding_model(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE)\n",
        "loss_function = nn.BCELoss()\n",
        "optimizer = optim.SGD(model1.parameters(), lr = 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSrhT-JTh-XE"
      },
      "outputs": [],
      "source": [
        "class word2vec_model(torch.nn.Module) :\n",
        "    def __init__(self, embedding_dim, hidden_dim) :\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.linear = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.dropout(x)\n",
        "        lstm_out, (ht, ct) = self.lstm(x)\n",
        "        return torch.sigmoid(self.linear(ht[-1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEW4qo8sh-XE"
      },
      "outputs": [],
      "source": [
        "model2 = word2vec_model(vector_size, 50)\n",
        "optimizer2 = optim.Adam(model2.parameters(), lr = 0.0002)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7n84WI2LjS0N"
      },
      "source": [
        "## Train & Test\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5oVylVSh-XE"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, optimizer):\n",
        "    i = 0\n",
        "    for sentence, label in train_loader:\n",
        "        model.zero_grad()\n",
        "        tag_scores = model(sentence)\n",
        "        label = np.reshape(label, [batch_size, 1])\n",
        "        loss = loss_function(tag_scores, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        i += 50\n",
        "        if i % 5000 == 0:\n",
        "            print(str(i) + \"/40000\")\n",
        "\n",
        "\n",
        "def test(model, valid_dl):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    sum_loss = 0.0\n",
        "    sum_rmse = 0.0\n",
        "    with torch.no_grad():\n",
        "        for x, y in valid_dl:\n",
        "            y_hat = model(x)\n",
        "            y = np.reshape(y, [batch_size, 1])\n",
        "            loss = loss_function(y_hat, y)\n",
        "            pred = torch.max(y_hat, 1)[1]\n",
        "            total += y.shape[0]\n",
        "            sum_loss += loss.item() * y.shape[0]\n",
        "            for i in range(batch_size):\n",
        "                if abs(y[i] - y_hat[i]) < 0.5:\n",
        "                    correct += 1\n",
        "\n",
        "    print(\"sum_loss:\", sum_loss)\n",
        "    print(\"accuracy:\", correct/total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfZJ0FSrjaJ3",
        "outputId": "70ed3208-1e63-4bd2-8384-209d3ce9dd2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1\n",
            "5000/40000\n",
            "10000/40000\n",
            "15000/40000\n",
            "20000/40000\n",
            "25000/40000\n",
            "30000/40000\n",
            "35000/40000\n",
            "40000/40000\n",
            "sum_loss: 6648.838910460472\n",
            "accuracy: 0.5899\n",
            "epoch 2\n",
            "5000/40000\n",
            "10000/40000\n",
            "15000/40000\n",
            "20000/40000\n",
            "25000/40000\n",
            "30000/40000\n",
            "35000/40000\n",
            "40000/40000\n",
            "sum_loss: 5837.502163648605\n",
            "accuracy: 0.6802\n",
            "epoch 3\n",
            "5000/40000\n",
            "10000/40000\n",
            "15000/40000\n",
            "20000/40000\n",
            "25000/40000\n",
            "30000/40000\n",
            "35000/40000\n",
            "40000/40000\n",
            "sum_loss: 4895.749546587467\n",
            "accuracy: 0.7652\n",
            "epoch 4\n",
            "5000/40000\n",
            "10000/40000\n",
            "15000/40000\n",
            "20000/40000\n",
            "25000/40000\n",
            "30000/40000\n",
            "35000/40000\n",
            "40000/40000\n",
            "sum_loss: 4383.436493575573\n",
            "accuracy: 0.7986\n",
            "epoch 5\n",
            "5000/40000\n",
            "10000/40000\n",
            "15000/40000\n",
            "20000/40000\n",
            "25000/40000\n",
            "30000/40000\n",
            "35000/40000\n",
            "40000/40000\n",
            "sum_loss: 5345.810254663229\n",
            "accuracy: 0.7646\n",
            "epoch 6\n",
            "5000/40000\n",
            "10000/40000\n",
            "15000/40000\n",
            "20000/40000\n",
            "25000/40000\n",
            "30000/40000\n",
            "35000/40000\n",
            "40000/40000\n",
            "sum_loss: 4091.991976648569\n",
            "accuracy: 0.8198\n",
            "epoch 7\n",
            "5000/40000\n",
            "10000/40000\n",
            "15000/40000\n",
            "20000/40000\n",
            "25000/40000\n",
            "30000/40000\n",
            "35000/40000\n",
            "40000/40000\n",
            "sum_loss: 4132.701239734888\n",
            "accuracy: 0.8159\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(7):\n",
        "    print(\"epoch \" + str(epoch + 1))\n",
        "    train(model1, train_loader1, optimizer)\n",
        "    test(model1, test_loader1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJgnjW_zh-XF",
        "outputId": "cb4b3bad-c3ec-45dd-8a1e-386d290f3326"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1\n",
            "5000/40000\n",
            "10000/40000\n",
            "15000/40000\n",
            "20000/40000\n",
            "25000/40000\n",
            "30000/40000\n",
            "35000/40000\n",
            "40000/40000\n",
            "sum_loss: 6846.103611588478\n",
            "accuracy: 0.5229\n",
            "epoch 2\n",
            "5000/40000\n",
            "10000/40000\n",
            "15000/40000\n",
            "20000/40000\n",
            "25000/40000\n",
            "30000/40000\n",
            "35000/40000\n",
            "40000/40000\n",
            "sum_loss: 5635.551688075066\n",
            "accuracy: 0.7381\n",
            "epoch 3\n",
            "5000/40000\n",
            "10000/40000\n",
            "15000/40000\n",
            "20000/40000\n",
            "25000/40000\n",
            "30000/40000\n",
            "35000/40000\n",
            "40000/40000\n",
            "sum_loss: 6063.335801661015\n",
            "accuracy: 0.6652\n",
            "epoch 4\n",
            "5000/40000\n",
            "10000/40000\n",
            "15000/40000\n",
            "20000/40000\n",
            "25000/40000\n",
            "30000/40000\n",
            "35000/40000\n",
            "40000/40000\n",
            "sum_loss: 5513.767635822296\n",
            "accuracy: 0.7573\n",
            "epoch 5\n",
            "5000/40000\n",
            "10000/40000\n",
            "15000/40000\n",
            "20000/40000\n",
            "25000/40000\n",
            "30000/40000\n",
            "35000/40000\n",
            "40000/40000\n",
            "sum_loss: 5595.515322685242\n",
            "accuracy: 0.7369\n",
            "epoch 6\n",
            "5000/40000\n",
            "10000/40000\n",
            "15000/40000\n",
            "20000/40000\n",
            "25000/40000\n",
            "30000/40000\n",
            "35000/40000\n",
            "40000/40000\n",
            "sum_loss: 6030.070298910141\n",
            "accuracy: 0.6928\n",
            "epoch 7\n",
            "5000/40000\n",
            "10000/40000\n",
            "15000/40000\n",
            "20000/40000\n",
            "25000/40000\n",
            "30000/40000\n",
            "35000/40000\n",
            "40000/40000\n",
            "sum_loss: 5126.0120287537575\n",
            "accuracy: 0.7876\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(7):\n",
        "    print(\"epoch \" + str(epoch + 1))\n",
        "    train(model2, train_loader2, optimizer2)\n",
        "    test(model2, test_loader2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjX3C0hXjTy3"
      },
      "source": [
        "## Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHNg4lkDh-XG",
        "outputId": "8dfdec92-5292-4bac-8f6f-b0191c2873c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('.', 1), ('movie', 2), ('film', 3), (\"''\", 4), ('``', 5), ('one', 6), ('!', 7), ('like', 8), ('?', 9), ('good', 10)]\n"
          ]
        }
      ],
      "source": [
        "# visualizing the trainable embeddings for the 20 most popular tokens using TSNE\n",
        "\n",
        "import ast\n",
        "tokenizer_config = tokenizer.get_config()\n",
        "words_indices = ast.literal_eval(tokenizer_config[\"word_index\"])\n",
        "print(list(words_indices.items())[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSR5QR-Ch-XG"
      },
      "outputs": [],
      "source": [
        "words_embeddings = {}\n",
        "for word, index in list(words_indices.items())[:10000]:\n",
        "    index = torch.tensor(index)\n",
        "    embedding = model1.return_embeddings(index)\n",
        "    words_embeddings[word] = embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMoD5Dwwh-XG"
      },
      "outputs": [],
      "source": [
        "words = list(words_embeddings.keys())\n",
        "embeddings = list(words_embeddings.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLTzuWg5h-XH"
      },
      "outputs": [],
      "source": [
        "for i in range(len(embeddings)):\n",
        "    embeddings[i] = embeddings[i].tolist()\n",
        "embeddings = np.array(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3KVCEJMh-XH"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "squeezed_embeddings = TSNE(n_components=2).fit_transform(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBr8l2hEh-XH",
        "outputId": "75f470d5-53c9-4133-9f1c-bffd9f4ab4f3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(squeezed_embeddings[:20, 0], squeezed_embeddings[:20, 1])\n",
        "\n",
        "for i, txt in enumerate(words[:20]):\n",
        "    ax.annotate(words[i], (squeezed_embeddings[i][0], squeezed_embeddings[i][1]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}